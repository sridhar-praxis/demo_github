{
 "cells": [
  {
   "cell_type": "raw",
   "id": "66f556aa",
   "metadata": {},
   "source": [
    "https://insidelearningmachines.com/adaboost_regression_algorithm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c1583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Regression Train MAPE: 2.173933907471666\n",
      "Adaboost Regression Test MAPE: 2.944399207297575\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def generate_data():\n",
    "    X = np.random.rand(500, 2)\n",
    "    y = np.random.rand(500)\n",
    "    return X, y\n",
    "\n",
    "def fit_adaboost_regressor(X, y, num_stumps):\n",
    "    n_samples = X.shape[0]\n",
    "    # Initialize weights to 1/n_samples\n",
    "    sample_weights = np.full(n_samples, (1 / n_samples))\n",
    "    stumps = []\n",
    "    stump_weights = []\n",
    "    for _ in range(num_stumps):\n",
    "        # Fit a decision tree to the data using the current weights\n",
    "        stump = DecisionTreeRegressor(max_depth=1, max_leaf_nodes=2)\n",
    "        stump.fit(X, y, sample_weight=sample_weights)\n",
    "        # Predict the labels and calculate the loss\n",
    "        y_pred = stump.predict(X)\n",
    "        loss = np.abs(y - y_pred) / np.max(np.abs(y - y_pred))\n",
    "        # Calculate the weighted error rate and stump weight\n",
    "        weighted_error = np.sum(sample_weights * loss)\n",
    "        stump_weight = np.log((1 - weighted_error) / weighted_error)\n",
    "        # Update the sample weights for the next iteration\n",
    "        sample_weights *= np.exp(stump_weight * loss)\n",
    "        sample_weights /= np.sum(sample_weights)\n",
    "        # Save the stump and its weight\n",
    "        stumps.append(stump)\n",
    "        stump_weights.append(stump_weight)\n",
    "    return stumps, stump_weights\n",
    "\n",
    "def predict_adaboost_regressor(X, stumps, stump_weights):\n",
    "    n_samples = X.shape[0]\n",
    "    y_pred = np.zeros(n_samples)\n",
    "    for i in range(len(stumps)):\n",
    "        y_pred += stump_weights[i] * stumps[i].predict(X)\n",
    "    return y_pred\n",
    "\n",
    "def evaluate_mape(y_true, y_pred):\n",
    "    return mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "# Generate the data and split into train and test sets\n",
    "X, y = generate_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the adaboost regressor and make predictions\n",
    "adaboost_stumps, adaboost_stump_weights = fit_adaboost_regressor(X_train, y_train, num_stumps=50)\n",
    "adaboost_y_train_pred = predict_adaboost_regressor(X_train, adaboost_stumps, adaboost_stump_weights)\n",
    "adaboost_y_test_pred = predict_adaboost_regressor(X_test, adaboost_stumps, adaboost_stump_weights)\n",
    "\n",
    "# Evaluate the performance of the adaboost regressor using MAPE\n",
    "adaboost_train_mape = evaluate_mape(y_train, adaboost_y_train_pred)\n",
    "adaboost_test_mape = evaluate_mape(y_test, adaboost_y_test_pred)\n",
    "\n",
    "print(\"Adaboost Regression Train MAPE:\", adaboost_train_mape)\n",
    "print(\"Adaboost Regression Test MAPE:\", adaboost_test_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b159d876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn AdaboostRegressor Train MAPE: 256.42%\n",
      "Sklearn AdaboostRegressor Test MAPE: 343.80%\n"
     ]
    }
   ],
   "source": [
    "# Use the sklearn AdaboostRegressor as a comparison\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Train the sklearn AdaboostRegressor and make predictions\n",
    "sklearn_adaboost = AdaBoostRegressor(n_estimators=50, learning_rate=1)\n",
    "sklearn_adaboost.fit(X_train, y_train)\n",
    "sklearn_y_train_pred = sklearn_adaboost.predict(X_train)\n",
    "sklearn_y_test_pred = sklearn_adaboost.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the sklearn AdaboostRegressor using MAPE\n",
    "sklearn_train_mape = mean_absolute_percentage_error(y_train, sklearn_y_train_pred)\n",
    "sklearn_test_mape = mean_absolute_percentage_error(y_test, sklearn_y_test_pred)\n",
    "\n",
    "print(\"Sklearn AdaboostRegressor Train MAPE: {:.2f}%\".format(sklearn_train_mape * 100))\n",
    "print(\"Sklearn AdaboostRegressor Test MAPE: {:.2f}%\".format(sklearn_test_mape * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f31584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 1, 'n_estimators': 50}\n",
      "Tuned sklearn AdaboostRegressor MAPE - Train: 2.518053641005037\n",
      "Tuned sklearn AdaboostRegressor MAPE - Test: 3.423859236833386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'n_estimators': [10, 50, 100],\n",
    "              'learning_rate': [0.1, 0.5, 1]}\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(AdaBoostRegressor(), param_grid, scoring='neg_mean_absolute_percentage_error', cv=5)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Make predictions using the best estimator found\n",
    "sklearn_adaboost_tuned = grid_search.best_estimator_\n",
    "sklearn_y_train_pred_tuned = sklearn_adaboost_tuned.predict(X_train)\n",
    "sklearn_y_test_pred_tuned = sklearn_adaboost_tuned.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the tuned sklearn AdaboostRegressor using MAPE\n",
    "sklearn_train_mape_tuned = mean_absolute_percentage_error(y_train, sklearn_y_train_pred_tuned)\n",
    "sklearn_test_mape_tuned = mean_absolute_percentage_error(y_test, sklearn_y_test_pred_tuned)\n",
    "print(\"Tuned sklearn AdaboostRegressor MAPE - Train:\", sklearn_train_mape_tuned)\n",
    "print(\"Tuned sklearn AdaboostRegressor MAPE - Test:\", sklearn_test_mape_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c26421ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAPE: 8.892400504139253\n",
      "Test MAPE: 7.950289928679891\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit_adaboost_regressor(X_train, y_train, n_estimators, eta):\n",
    "    n_samples, n_features = X_train.shape\n",
    "    weights = np.ones(n_samples) / n_samples\n",
    "    stumps = []\n",
    "    alphas = []\n",
    "    \n",
    "    for _ in range(n_estimators):\n",
    "        stump = DecisionTreeRegressor(max_depth=1)\n",
    "        stump.fit(X_train, y_train, sample_weight=weights)\n",
    "        y_train_pred = stump.predict(X_train)\n",
    "        error = np.mean(weights * np.exp(-y_train * y_train_pred))\n",
    "        alpha = 0.5 * np.log((1 - error) / error)\n",
    "        weights = weights * np.exp(-alpha * (y_train * y_train_pred))\n",
    "        weights /= np.sum(weights)\n",
    "        stumps.append(stump)\n",
    "        alphas.append(alpha)\n",
    "    \n",
    "    return stumps, alphas\n",
    "\n",
    "def predict_adaboost_regressor(X, stumps, alphas):\n",
    "    y_pred = np.zeros(len(X))\n",
    "    for stump, alpha in zip(stumps, alphas):\n",
    "        y_pred += alpha * stump.predict(X)\n",
    "    return y_pred\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "# Generate synthetic dataset\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(500, 2)\n",
    "y = np.random.rand(500)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit adaboost regression using exponential loss\n",
    "n_estimators = 50\n",
    "adaboost_fit = fit_adaboost_regressor(X_train, y_train, n_estimators, eta)\n",
    "\n",
    "# Make predictions on train and test sets\n",
    "y_train_pred = predict_adaboost_regressor(X_train, *adaboost_fit)\n",
    "y_test_pred = predict_adaboost_regressor(X_test, *adaboost_fit)\n",
    "\n",
    "# Evaluate performance using MAPE\n",
    "train_mape = mape(y_train, y_train_pred)\n",
    "test_mape = mape(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train MAPE:\", train_mape)\n",
    "print(\"Test MAPE:\", test_mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07ed4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_adaboost_regressor(X_train, y_train, X_val, y_val, n_estimators_list, eta_list):\n",
    "    best_hyperparams = None\n",
    "    best_val_mape = float('inf')\n",
    "    adaboost_model = None\n",
    "    \n",
    "    for n_estimators in n_estimators_list:\n",
    "        for eta in eta_list:\n",
    "            # Fit adaboost regression using exponential loss\n",
    "            adaboost_fit = fit_adaboost_regressor(X_train, y_train, n_estimators, eta)\n",
    "\n",
    "            # Make predictions on train and validation sets\n",
    "            y_train_pred = predict_adaboost_regressor(X_train, *adaboost_fit)\n",
    "            y_val_pred = predict_adaboost_regressor(X_val, *adaboost_fit)\n",
    "\n",
    "            # Evaluate performance using MAPE\n",
    "            train_mape = mape(y_train, y_train_pred)\n",
    "            val_mape = mape(y_val, y_val_pred)\n",
    "\n",
    "            # Update best hyperparameters if we have found a better model\n",
    "            if val_mape < best_val_mape:\n",
    "                best_hyperparams = {'n_estimators': n_estimators, 'eta': eta}\n",
    "                best_val_mape = val_mape\n",
    "                adaboost_model = adaboost_fit\n",
    "                \n",
    "    return best_hyperparams, train_mape, best_val_mape, adaboost_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53dbdb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters: {'n_estimators': 50, 'eta': 1.0}\n",
      "Train MAPE: 208.44131540397265\n",
      "Validation MAPE: 89.5301253449452\n",
      "Test MAPE: 91.74265496239677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define hyperparameters to search over\n",
    "n_estimators_list = [50, 100, 200]\n",
    "eta_list = [0.1, 0.5, 1.0]\n",
    "\n",
    "# Perform grid search\n",
    "best_hyperparams, train_mape, val_mape, adaboost_model = grid_search_adaboost_regressor(X_train, y_train, X_val, y_val, n_estimators_list, eta_list)\n",
    "\n",
    "# Evaluate performance on test set using best model\n",
    "test_mape = mape(y_test, predict_adaboost_regressor(X_test, *adaboost_model))\n",
    "print(\"\\nBest hyperparameters:\", best_hyperparams)\n",
    "print(\"Train MAPE:\", train_mape)\n",
    "print(\"Validation MAPE:\", val_mape)\n",
    "print(\"Test MAPE:\", test_mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f4f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
